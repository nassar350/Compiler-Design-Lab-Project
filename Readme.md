# C Compiler Frontend: Lexical Analyzer (Scanner) + Syntax Analyzer (Parser)

A comprehensive compiler frontend implementation in Python that performs both lexical analysis and syntax analysis for C-like source code. The project consists of a complete scanner (tokenizer) and a recursive-descent parser that validates syntax according to a formal grammar specification.

---

## ğŸ—‚ Project Structure

```
Design Project (Scanner + Parser)/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lexer/
â”‚   â”‚   â”œâ”€â”€ token.py            # Token class definition
â”‚   â”‚   â”œâ”€â”€ token_types.py      # Token type enum
â”‚   â”‚   â”œâ”€â”€ scanner.py          # Helper methods for token classification
â”‚   â”‚   â””â”€â”€ tokenizer.py        # Main tokenizer logic (lexical analysis)
â”‚   â”‚
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ Grammar.txt         # Formal BNF grammar specification
â”‚   â”‚   â””â”€â”€ parser.py           # Recursive-descent parser implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ sources/            # Test case suite (12 test files)
â”‚   â”‚       â”œâ”€â”€ 01_minimal_fun.c              # Basic function
â”‚   â”‚       â”œâ”€â”€ 02_var_decls.c                # Variable declarations
â”‚   â”‚       â”œâ”€â”€ 03_fun_with_params.c          # Functions with parameters
â”‚   â”‚       â”œâ”€â”€ 04_compound_local_decls.c     # Local scope variables
â”‚   â”‚       â”œâ”€â”€ 05_if_else.c                  # If/else statements
â”‚   â”‚       â”œâ”€â”€ 06_while_for.c                # Loop statements
â”‚   â”‚       â”œâ”€â”€ 07_calls_args.c               # Function calls
â”‚   â”‚       â”œâ”€â”€ 08_logical_relational.c       # Logical/relational ops
â”‚   â”‚       â”œâ”€â”€ 09_return_expr_opt.c          # Return statements
â”‚   â”‚       â”œâ”€â”€ 10_invalid_missing_semicolon.c # Error test
â”‚   â”‚       â”œâ”€â”€ 11_invalid_unmatched_paren.c  # Error test
â”‚   â”‚       â””â”€â”€ 12_invalid_unknown_type.c     # Error test
â”‚   â”‚
â”‚   â”œâ”€â”€ IO/
â”‚   â”‚   â”œâ”€â”€ file_reader.py      # Reads source code from file
â”‚   â”‚   â””â”€â”€ file_writer.py      # Writes tokens to output file
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py                 # Entry point (CLI) - integrates scanner + parser
â”‚   â”œâ”€â”€ SourceCode.c            # Sample C source code for testing
â”‚   â””â”€â”€ result.json             # Token output file
â”‚
â””â”€â”€ Readme.md
```
---

## âš¡ Features

### Lexical Analyzer (Scanner)
- **Comprehensive Token Recognition:**
  - **Keywords** (`int`, `float`, `void`, `if`, `else`, `while`, `for`, `return`)
  - **Identifiers** (variable/function names)
  - **Operators** (`+`, `-`, `*`, `/`, `=`, `==`, `!=`, `<`, `<=`, `>`, `>=`, `&&`, `||`)
  - **Numeric Constants** (integers and floats)
  - **Character Constants** (`'a'`, `'1'`)
  - **Special Characters** (`(){}[];,#.`)
  - **Comments** (`// single-line`, `/* multi-line */`)
  - **Whitespace & Newlines**
- Token statistics and summary reporting
- JSON output for token sequences

### Syntax Analyzer (Parser)
- **Recursive-Descent Parser** implementation
- **Complete Grammar Support** for C-like syntax:
  - Program structure with declarations
  - Variable declarations (single and multiple)
  - Function declarations with parameters
  - Compound statements with local variables
  - Control flow statements (`if`/`else`, `while`, `for`, `return`)
  - Expression parsing with proper precedence:
    - Assignment expressions
    - Logical operators (`||`, `&&`)
    - Relational operators (`<`, `<=`, `>`, `>=`, `==`, `!=`)
    - Arithmetic operators (`+`, `-`, `*`, `/`)
  - Function calls with arguments
  - Parenthesized expressions
- **Smart Trivia Handling**: Automatically skips comments, whitespace, and newlines during parsing
- **Enhanced Error Reporting**: 
  - Line and column number tracking for precise error location
  - Format: `Syntax Error at line:column.`
  - Clear error messages with token context
- **Lookahead Support**: Multi-token lookahead for disambiguation
- **Comprehensive Test Suite**: 12 test cases covering valid and invalid syntax

---

## ğŸ’» Requirements

- Python 3.7+
- No external dependencies (uses built-in modules like `re` and `argparse`)

---

## ğŸš€ Usage

### Command-Line Interface

```bash
python main.py input_file.c -o tokens_output.json
```
- `input_file.c` â†’ Source code file to tokenize and parse
- `-o tokens_output.json` â†’ Optional output file to save tokens

### Execution Flow

1. **Lexical Analysis**: Source code is tokenized into a stream of tokens
2. **Token Statistics**: Display token counts by type
3. **Syntax Analysis**: Parser validates the token stream against grammar rules
4. **Result**: Outputs "Syntax: OK" if valid, or reports syntax errors with details
5. **Output**: Optionally writes tokens to specified file

### Example

```bash
python .\main.py .\SourceCode.c
```

---

## ğŸ“Š Example Output

### Sample Input (SourceCode.c)
```c
int main() {
    int x, y;
    if (x == 42) {
        x = x - 3;
    } else {
        y = 3.1;
    }
    return 0;
}
```

### Console Output
```
Total Tokens: 45

Token Type Counts:
  KEYWORD         : 5
  IDENTIFIER      : 6
  OPERATOR        : 5
  NUMERIC_CONSTANT: 3
  SPECIAL_CHARACTER: 20
  COMMENT         : 3
  WHITESPACE      : 2
  NEWLINE         : 1

Tokens:
[Token (int,TokenType.KEYWORD), Token (main,TokenType.IDENTIFIER), ...]

==============================

Syntax: OK
âœ… Tokens written to result.json
```
---

## ğŸ”§ How It Works

### Phase 1: Lexical Analysis (Scanner)

1. `main.py` reads the input source file via `file_reader.py`
2. `Tokenizer` uses regex patterns and helper methods in `Scanner` to classify each lexeme
3. Tokens are stored as instances of the `Token` class with an associated `TokenType`
4. A summary of token counts by type is displayed
5. Token stream is passed to the parser

### Phase 2: Syntax Analysis (Parser)

1. `Parser` receives the token stream from the tokenizer
2. Implements recursive-descent parsing based on formal grammar (`Grammar.txt`)
3. Each non-terminal in the grammar has a corresponding `parse_*` method
4. Parser automatically skips trivia (comments, whitespace, newlines) during analysis
5. Uses lookahead to disambiguate grammar productions (e.g., variable vs function declaration)
6. Validates proper nesting of scopes and statement structures
7. Reports syntax errors with descriptive messages if validation fails
8. Confirms successful parse with "Syntax: OK" message

### Key Parser Features

- **Trivia Handling**: `_skip_trivia()` automatically ignores whitespace/comments between tokens
- **Lookahead**: `peek(n)` allows multi-token lookahead for parsing decisions
- **Error Recovery**: Clear error messages indicating expected vs actual tokens
- **Grammar Coverage**: Full implementation of C-like syntax including expressions, statements, and declarations

---

## ğŸ“Š Token Types

| Token Type            | Example                     | Description                               |
|-----------------------|-----------------------------|-------------------------------------------|
| KEYWORD               | `int`, `float`, `if`, `while` | Reserved words in the language          |
| IDENTIFIER            | `x`, `main`, `myVar`        | Variable or function names                |
| OPERATOR              | `+`, `-`, `==`, `&&`        | Arithmetic, relational, logical operators |
| NUMERIC_CONSTANT      | `42`, `3.14`                | Integer or floating-point numbers         |
| CHARACTER_CONSTANT    | `'a'`, `'1'`                | Single character literals                 |
| SPECIAL_CHARACTER     | `(`, `)`, `{`, `}`, `;`     | Punctuation and delimiters               |
| COMMENT               | `// ...`, `/* ... */`       | Single-line or multi-line comments       |
| WHITESPACE            | ` `, `\t`                   | Spaces and tabs                          |
| NEWLINE               | `\n`                        | Line breaks                              |

---

## ğŸ“ Grammar Specification

The parser implements a complete C-like grammar defined in `Grammar.txt`. Key grammar rules include:

### Program Structure
```
Program        â†’ DeclList EOF
DeclList       â†’ Decl DeclList | Îµ
Decl           â†’ VarDecl | FunDecl
```

### Declarations
```
VarDecl        â†’ TypeSpec ID VarDeclTail ;
FunDecl        â†’ TypeSpec ID ( ParamList ) CompoundStmt
TypeSpec       â†’ int | float | void
```

### Statements
```
Stmt           â†’ ExprStmt | CompoundStmt | IfStmt | WhileStmt | ForStmt | ReturnStmt
IfStmt         â†’ if ( Expr ) Stmt ElsePart
WhileStmt      â†’ while ( Expr ) Stmt
ForStmt        â†’ for ( ForInitExpr ; ForCondExpr ; ForIterExpr ) Stmt
ReturnStmt     â†’ return ExprOpt ;
```

### Expressions (with precedence)
```
Expr           â†’ AssignExpr
AssignExpr     â†’ ID = AssignExpr | OrExpr
OrExpr         â†’ AndExpr OrExprTail
AndExpr        â†’ RelExpr AndExprTail
RelExpr        â†’ AddExpr RelOpTail
AddExpr        â†’ Term AddExprTail
Term           â†’ Factor TermTail
Factor         â†’ ( Expr ) | ID FactorTail | Literal
```

*See `Grammar.txt` for complete grammar specification.*

---

## ğŸ›  Implementation Details

### Parser Architecture

- **Class**: `Parser` in `parser.py`
- **Method**: Recursive-descent with predictive parsing
- **Token Management**: 
  - `peek(n)` - Look ahead n tokens (skipping trivia)
  - `advance()` - Consume current token
  - `expect(type, lexeme)` - Validate and consume expected token
- **Error Handling**: Raises `ParserError` with descriptive messages

### Key Parser Methods

| Method | Grammar Rule | Description |
|--------|--------------|-------------|
| `parse_program()` | Program â†’ DeclList EOF | Entry point |
| `parse_decl()` | Decl â†’ VarDecl \| FunDecl | Declaration with lookahead |
| `parse_compound_stmt()` | CompoundStmt â†’ { ... } | Scoped block |
| `parse_expr()` | Expr â†’ AssignExpr | Expression entry |
| `parse_assign_expr()` | AssignExpr â†’ ID = ... | Assignment with lookahead |
| `parse_factor()` | Factor â†’ ... | Primary expressions |

### Lookahead Strategy

The parser uses lookahead to disambiguate:
- **Variable vs Function**: After `TypeSpec ID`, checks for `(` to distinguish
- **Assignment vs Expression**: After `ID`, checks for `=` operator
- **Statement boundaries**: Identifies statement types by first keyword/symbol

---

## ğŸ§ª Testing

### Test Suite Structure
The project includes a comprehensive test suite in `src/tests/sources/` with 12 test cases:

**Valid Syntax Tests (01-09):**
- `01_minimal_fun.c` - Minimal function definition
- `02_var_decls.c` - Variable declarations (single and multiple)
- `03_fun_with_params.c` - Functions with parameters
- `04_compound_local_decls.c` - Compound statements with local variables
- `05_if_else.c` - If/else control flow
- `06_while_for.c` - While and for loops
- `07_calls_args.c` - Function calls with arguments
- `08_logical_relational.c` - Logical and relational operators
- `09_return_expr_opt.c` - Return statements with expressions

**Invalid Syntax Tests (10-12):**
- `10_invalid_missing_semicolon.c` - Missing semicolon error
- `11_invalid_unmatched_paren.c` - Unmatched parenthesis error
- `12_invalid_unknown_type.c` - Unknown type specifier error

### Running Tests

**Single Test:**
```bash
cd src
python main.py tests/sources/01_minimal_fun.c
```

**With Output File:**
```bash
python main.py SourceCode.c -o result.json
```

**Expected Output:**
- Valid files: `Syntax: OK`
- Invalid files: `Syntax Error at line:column.` with details

---

## ğŸ¯ Current Status

### âœ… Completed Features

**Scanner (Lexical Analyzer):**
- âœ… Complete tokenization of C-like syntax
- âœ… All token types recognized (keywords, identifiers, operators, literals, special chars)
- âœ… Single-line and multi-line comment handling
- âœ… Token statistics and reporting
- âœ… JSON output generation

**Parser (Syntax Analyzer):**
- âœ… Full recursive-descent parser implementation
- âœ… Complete grammar coverage for C-like language
- âœ… Variable declarations (single and multiple)
- âœ… Function declarations with parameters
- âœ… Compound statements with local scopes
- âœ… Control flow (`if`/`else`, `while`, `for`, `return`)
- âœ… Expression parsing with proper precedence
- âœ… Assignment expressions
- âœ… Logical operators (`||`, `&&`)
- âœ… Relational operators (`<`, `<=`, `>`, `>=`, `==`, `!=`)
- âœ… Arithmetic operators (`+`, `-`, `*`, `/`)
- âœ… Function calls with arguments
- âœ… Parenthesized expressions
- âœ… Trivia handling (auto-skip whitespace/comments)
- âœ… Multi-token lookahead support
- âœ… Enhanced error reporting with line:column tracking
- âœ… Comprehensive test suite (12 test cases: 9 valid, 3 invalid)
- âœ… Structured test organization in `tests/sources/`

---

## ğŸ› Known Issues

- No recovery mechanism - parsing stops at first syntax error
- Character constants recognized but not fully validated
- Limited error message detail (could include expected token information)

---

## ğŸš§ Future Enhancements

1. **Full C Compliance**: Extend grammar to support complete C syntax
2. **Optimization Passes**: Implement compiler optimization techniques
3. **Target Code Generation**: Generate executable code for specific architectures
4. **Interactive Mode**: REPL for testing expressions and statements
5. **Debug Mode**: Verbose output showing parser state transitions
6. **Performance**: Optimize tokenization and parsing for large files

---

## ğŸ“š References

- **Compiler Design Theory**: Aho, Sethi, Ullman - "Compilers: Principles, Techniques, and Tools"
- **Recursive-Descent Parsing**: Top-down predictive parsing technique
- **C Language Specification**: ANSI C / ISO C standards
- **Python Implementation**: Modern Python 3.7+ features (type hints, f-strings)

---

## ğŸ‘¥ Project Information

**Course**: Compiler Design Lab  
**Institution**: College  
**Branch**: main  
**Last Updated**: December 11, 2025

---

## ğŸ“„ License

This project is developed for educational purposes as part of a Compiler Design course.
